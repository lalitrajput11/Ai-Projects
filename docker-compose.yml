version: '3.8'

services:
  # AI Agent Service
  agent:
    build: .
    container_name: autonomous-agent
    ports:
      - "8000:8000"
    environment:
      - OLLAMA_HOST=http://host.docker.internal:11434
      - OLLAMA_MODEL=llama3.2:3b
      - AGENT_HOST=0.0.0.0
      - AGENT_PORT=8000
      - MCP_HOST=mcp-server
      - MCP_PORT=8001
      - MEMORY_DB_PATH=/app/data/agent_memory.db
      - MEMORY_JSON_PATH=/app/data/agent_memory.json
      - LOG_LEVEL=INFO
    volumes:
      - ./data:/app/data
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - mcp-server
    networks:
      - agent-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G

  # MCP Server Service
  mcp-server:
    build: .
    container_name: mcp-server
    command: ["python", "-m", "mcp_server.server"]
    ports:
      - "8001:8001"
    environment:
      - MCP_HOST=0.0.0.0
      - MCP_PORT=8001
      - LOG_LEVEL=INFO
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./data:/app/data
    networks:
      - agent-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

networks:
  agent-network:
    driver: bridge

volumes:
  data:
